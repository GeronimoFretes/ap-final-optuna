{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea29a31a",
   "metadata": {},
   "source": [
    "### En este archivo se entrena el modelo final, se guarda y se evalúan sus predicciones para el 2024, a modo de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8dbd7",
   "metadata": {},
   "source": [
    "Si ya hay un modelo entrenado y guardado, no se entrena nuevamente. Solamente se evalúan las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642aeb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from run_optuna import compute_past_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c0f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\", \"data/final_dataset.parquet\"))\n",
    "ARTIFACTS_DIR = Path(os.getenv(\"ARTIFACTS_DIR\", \"artifacts\"))\n",
    "\n",
    "TRAIN_YEAR = int(os.getenv(\"TRAIN_YEAR\", \"2023\"))\n",
    "EVAL_YEAR = int(os.getenv(\"EVAL_YEAR\", \"2024\"))\n",
    "\n",
    "BEST_TRIAL_PATH = Path(os.getenv(\"BEST_TRIAL_PATH\", \"artifacts/study_best.json\"))\n",
    "\n",
    "ENSEMBLE_DIR = Path(os.getenv(\"ENSEMBLE_DIR\", str(ARTIFACTS_DIR / f\"ensemble_train{TRAIN_YEAR}\")))\n",
    "ENSEMBLE_META_PATH = Path(\n",
    "    os.getenv(\"ENSEMBLE_META_PATH\", str(ARTIFACTS_DIR / f\"final_ensemble_train{TRAIN_YEAR}_meta.json\"))\n",
    ")\n",
    "\n",
    "FORCE_RETRAIN = os.getenv(\"FORCE_RETRAIN\", \"0\") == \"1\"\n",
    "\n",
    "REG_STRAT_BINS = int(os.getenv(\"REG_STRAT_BINS\", \"10\"))\n",
    "N_SPLITS = int(os.getenv(\"N_SPLITS\", \"5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f54a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helperss\n",
    "# ============================================================\n",
    "def make_regression_strat_bins(y: pd.Series, n_bins: int, n_splits: int):\n",
    "    \"\"\"\n",
    "    Create quantile bins for regression stratification.\n",
    "    Returns integer bin labels or None if we can't create valid bins.\n",
    "    \"\"\"\n",
    "    y = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "    for q in range(int(n_bins), 1, -1):\n",
    "        try:\n",
    "            b = pd.qcut(y, q=q, duplicates=\"drop\")\n",
    "            vc = b.value_counts()\n",
    "            if (vc < n_splits).any():\n",
    "                continue\n",
    "            return b.cat.codes.to_numpy()\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_cv_splitter(y: pd.Series, seed: int):\n",
    "    \"\"\"\n",
    "    Prefer StratifiedKFold on quantile bins. Fall back to KFold if binning fails.\n",
    "    Returns (splitter, strat_labels_or_none).\n",
    "    \"\"\"\n",
    "    strat = make_regression_strat_bins(y, REG_STRAT_BINS, N_SPLITS)\n",
    "    if strat is None:\n",
    "        return KFold(n_splits=N_SPLITS, shuffle=True, random_state=seed), None\n",
    "    return StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed), strat\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build X/y exactly like your eval pipeline\n",
    "# ============================================================\n",
    "def build_x_and_y(df: pd.DataFrame, target_year: int, selected_features: list[str]):\n",
    "    id_candidates = [\"gid\", \"dept_id\", \"departamento_id\", \"id\", \"in1\"]\n",
    "    id_cols = [c for c in id_candidates if c in df.columns]\n",
    "\n",
    "    mask = df[\"totpobla_2022\"].notna()\n",
    "    ids = df.loc[mask, id_cols].copy() if id_cols else pd.DataFrame(index=df.loc[mask].index)\n",
    "\n",
    "    df_model = df.loc[mask].select_dtypes(\"number\").copy()\n",
    "\n",
    "    target_col = f\"dengue_incid_{target_year}\"\n",
    "    if target_col not in df_model.columns:\n",
    "        raise ValueError(f\"Target column {target_col} not found for year={target_year}.\")\n",
    "\n",
    "    y_true = np.log1p(df_model[target_col].astype(float))\n",
    "\n",
    "    X_all = compute_past_features(df_model, target_year)\n",
    "\n",
    "    missing = [f for f in selected_features if f not in X_all.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing selected features in X: {missing}\")\n",
    "\n",
    "    X = X_all[selected_features].copy()\n",
    "    return ids.reset_index(drop=True), X.reset_index(drop=True), pd.Series(y_true).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train ensemble (CV-fold models) from Optuna best\n",
    "# ============================================================\n",
    "def train_ensemble_models(df: pd.DataFrame):\n",
    "    if not BEST_TRIAL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Best trial JSON not found: {BEST_TRIAL_PATH}\")\n",
    "\n",
    "    best = json.loads(BEST_TRIAL_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    params = dict(best[\"params\"])\n",
    "    user_attrs = best.get(\"user_attrs\", {})\n",
    "\n",
    "    selected_features = user_attrs.get(\"selected_features\")\n",
    "    if not selected_features:\n",
    "        raise ValueError(\"selected_features not found in study_best.json user_attrs.\")\n",
    "\n",
    "    cv_seeds = user_attrs.get(\"cv_seeds\")\n",
    "    if not cv_seeds:\n",
    "        raise ValueError(\"cv_seeds not found in study_best.json user_attrs.\")\n",
    "\n",
    "    params.pop(\"top_k\", None)\n",
    "\n",
    "    base_cb_params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"eval_metric\": \"RMSE\",\n",
    "        \"verbose\": False,\n",
    "        \"allow_writing_files\": False,\n",
    "        \"task_type\": \"CPU\",\n",
    "        \"od_type\": \"Iter\",\n",
    "        \"od_wait\": 50,\n",
    "        **params,\n",
    "    }\n",
    "\n",
    "    _, X_train, y_train = build_x_and_y(df, TRAIN_YEAR, selected_features)\n",
    "\n",
    "    ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_files = []\n",
    "    per_model_info = []\n",
    "    used_stratified_any = False\n",
    "\n",
    "    for cv_seed in cv_seeds:\n",
    "        splitter, strat_labels = get_cv_splitter(y_train, seed=int(cv_seed))\n",
    "        used_stratified = strat_labels is not None\n",
    "        used_stratified_any = used_stratified_any or used_stratified\n",
    "\n",
    "        split_iter = splitter.split(X_train, strat_labels) if strat_labels is not None else splitter.split(X_train)\n",
    "\n",
    "        for fold_idx, (tr_idx, va_idx) in enumerate(split_iter):\n",
    "            model_path = ENSEMBLE_DIR / f\"model_seed{int(cv_seed)}_fold{fold_idx}.cbm\"\n",
    "\n",
    "            if model_path.exists() and not FORCE_RETRAIN:\n",
    "                model_files.append(str(model_path))\n",
    "                per_model_info.append(\n",
    "                    {\"cv_seed\": int(cv_seed), \"fold\": int(fold_idx), \"path\": str(model_path), \"trained\": False}\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "            y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "            cb_params = dict(base_cb_params)\n",
    "            cb_params[\"random_seed\"] = int(cv_seed) + int(fold_idx)\n",
    "\n",
    "            m = CatBoostRegressor(**cb_params)\n",
    "            m.fit(X_tr, y_tr, eval_set=(X_va, y_va), use_best_model=True)\n",
    "\n",
    "            m.save_model(str(model_path))\n",
    "            model_files.append(str(model_path))\n",
    "\n",
    "            per_model_info.append(\n",
    "                {\n",
    "                    \"cv_seed\": int(cv_seed),\n",
    "                    \"fold\": int(fold_idx),\n",
    "                    \"path\": str(model_path),\n",
    "                    \"trained\": True,\n",
    "                    \"best_iteration\": int(m.get_best_iteration()) if m.get_best_iteration() is not None else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    meta = {\n",
    "        \"train_year\": int(TRAIN_YEAR),\n",
    "        \"n_splits\": int(N_SPLITS),\n",
    "        \"reg_strat_bins\": int(REG_STRAT_BINS),\n",
    "        \"cv_seeds\": [int(s) for s in cv_seeds],\n",
    "        \"used_stratified_any\": bool(used_stratified_any),\n",
    "        \"selected_features\": list(selected_features),\n",
    "        \"catboost_params_base\": base_cb_params,\n",
    "        \"model_files\": model_files,\n",
    "        \"per_model_info\": per_model_info,\n",
    "        \"note\": \"Ensemble is the mean of CV-fold models (trained on K-1 folds each).\",\n",
    "    }\n",
    "\n",
    "    ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    ENSEMBLE_META_PATH.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[ensemble] saved meta → {ENSEMBLE_META_PATH}\")\n",
    "    print(f\"[ensemble] models in   → {ENSEMBLE_DIR}  (count={len(model_files)})\")\n",
    "\n",
    "    return meta\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Load ensemble and predict\n",
    "# ============================================================\n",
    "def load_ensemble_models(model_files: list[str]):\n",
    "    models = []\n",
    "    for p in model_files:\n",
    "        mp = Path(p)\n",
    "        if not mp.exists():\n",
    "            raise FileNotFoundError(f\"Ensemble model missing: {mp}\")\n",
    "        m = CatBoostRegressor()\n",
    "        m.load_model(str(mp))\n",
    "        models.append(m)\n",
    "    return models\n",
    "\n",
    "\n",
    "def ensemble_predict(models, X: pd.DataFrame):\n",
    "    preds = []\n",
    "    for m in models:\n",
    "        preds.append(m.predict(X))\n",
    "    preds = np.vstack(preds)\n",
    "    return preds.mean(axis=0), preds\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "    if ENSEMBLE_META_PATH.exists() and not FORCE_RETRAIN:\n",
    "        meta = json.loads(ENSEMBLE_META_PATH.read_text(encoding=\"utf-8\"))\n",
    "        model_files = meta.get(\"model_files\", [])\n",
    "        if not model_files:\n",
    "            print(\"[ensemble] meta exists but model_files empty → retraining.\")\n",
    "            meta = train_ensemble_models(df)\n",
    "    else:\n",
    "        meta = train_ensemble_models(df)\n",
    "\n",
    "    selected_features = meta[\"selected_features\"]\n",
    "    model_files = meta[\"model_files\"]\n",
    "\n",
    "    ids, X_eval, y_true = build_x_and_y(df, EVAL_YEAR, selected_features)\n",
    "\n",
    "    models = load_ensemble_models(model_files)\n",
    "    y_pred, preds_matrix = ensemble_predict(models, X_eval)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    out = pd.concat(\n",
    "        [\n",
    "            ids,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"y_true_log1p\": y_true,\n",
    "                    \"y_pred_log1p\": y_pred,\n",
    "                    \"y_true_incid\": np.expm1(y_true),\n",
    "                    \"y_pred_incid\": np.expm1(y_pred),\n",
    "                    \"residual_log1p\": (y_true - y_pred),\n",
    "                    \"n_models\": len(models),\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    pred_path = ARTIFACTS_DIR / f\"predictions_{EVAL_YEAR}_from_train{TRAIN_YEAR}_ensemble.csv\"\n",
    "    out.to_csv(pred_path, index=False)\n",
    "\n",
    "    metrics = {\n",
    "        \"train_year\": int(TRAIN_YEAR),\n",
    "        \"eval_year\": int(EVAL_YEAR),\n",
    "        \"metric_space\": \"log1p(incidence)\",\n",
    "        \"rmse\": float(rmse),\n",
    "        \"mae\": float(mae),\n",
    "        \"r2\": float(r2),\n",
    "        \"n_rows\": int(len(out)),\n",
    "        \"n_models\": int(len(models)),\n",
    "        \"ensemble_dir\": str(ENSEMBLE_DIR),\n",
    "        \"ensemble_meta\": str(ENSEMBLE_META_PATH),\n",
    "    }\n",
    "    metrics_path = ARTIFACTS_DIR / f\"metrics_{EVAL_YEAR}_from_train{TRAIN_YEAR}_ensemble.json\"\n",
    "    metrics_path.write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"=== {EVAL_YEAR} evaluation (ENSEMBLE) ===\")\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "    print(f\"Saved predictions → {pred_path}\")\n",
    "    print(f\"Saved metrics     → {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b94ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ensemble] saved meta → artifacts\\final_ensemble_train2023_meta.json\n",
      "[ensemble] models in   → artifacts\\ensemble_train2023  (count=15)\n",
      "=== 2024 evaluation (ENSEMBLE) ===\n",
      "{\n",
      "  \"train_year\": 2023,\n",
      "  \"eval_year\": 2024,\n",
      "  \"metric_space\": \"log1p(incidence)\",\n",
      "  \"rmse\": 3.0782757513415113,\n",
      "  \"mae\": 2.694206722801272,\n",
      "  \"r2\": -1.0176729681480925,\n",
      "  \"n_rows\": 527,\n",
      "  \"n_models\": 15,\n",
      "  \"ensemble_dir\": \"artifacts\\\\ensemble_train2023\",\n",
      "  \"ensemble_meta\": \"artifacts\\\\final_ensemble_train2023_meta.json\"\n",
      "}\n",
      "Saved predictions → artifacts\\predictions_2024_from_train2023_ensemble.csv\n",
      "Saved metrics     → artifacts\\metrics_2024_from_train2023_ensemble.json\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
